{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import print_function, division\n",
    "from keras.utils import plot_model\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, concatenate, Lambda, Reshape\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D, Conv2DTranspose, MaxPooling2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sys,os\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from PIL import Image\n",
    "from theano import tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_sum_exp(x, axis=None, keepdims=False):\n",
    "    '''Numerically stable log( sum( exp(A) ) ).\n",
    "    '''\n",
    "    x_max = K.max(x, axis=axis, keepdims=True)\n",
    "    y = K.log(K.sum(K.exp(x - x_max), axis=axis, keepdims=True)) + x_max\n",
    "    y = K.sum(y, axis=axis, keepdims=keepdims)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BGAN():\n",
    "    \"\"\"Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def build(self, imgshape, latentnum, path, optimizer=\"Adam\", nettype=\"FC\",g_lr=0.0002, d_lr=0.0002):\n",
    "#         self.img_rows = 28\n",
    "#         self.img_cols = 28\n",
    "#         self.channels = 1\n",
    "        self.img_shape = imgshape\n",
    "        self.latent_dim = latentnum\n",
    "        self.path=path\n",
    "        self.history=[]\n",
    "        if optimizer==\"Adam\":\n",
    "            g_opt=Adam(g_lr, 0.5)\n",
    "            d_opt=Adam(d_lr, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        if nntype==\"FC\":\n",
    "            self.discriminator = self.build_discriminator()\n",
    "        elif nntype==\"CNN\":\n",
    "            self.discriminator = self.build_discriminator_CNN()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=d_opt,\n",
    "            metrics=['accuracy'])\n",
    "        self.discriminator.summary()\n",
    "        \n",
    "        # Build the generator\n",
    "        if nntype==\"FC\":\n",
    "            self.generator = self.build_generator()\n",
    "        elif nntype==\"CNN\":\n",
    "            self.generator = self.build_generator_CNN()\n",
    "        self.generator.summary()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator(tensor)\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.boundary_loss, optimizer=g_opt)\n",
    "        self.combined.summary()\n",
    "    \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "    \n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "#         model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "#         model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def build_generator_CNN(self):\n",
    "        \n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        model=Dense(7*7*16, input_dim=self.latent_dim)(noise)\n",
    "        model=BatchNormalization()(model)\n",
    "        model=LeakyReLU(alpha=0.1)(model)\n",
    "#         model=Dense(512, activation=\"relu\")(model)\n",
    "#         model=LeakyReLU(alpha=0.2)(model)\n",
    "#         model=BatchNormalization()(model)\n",
    "        model=Reshape(target_shape=(7,7,16))(model)\n",
    "    \n",
    "        model=Conv2DTranspose(8, kernel_size=5, strides=2, padding=\"same\")(model)\n",
    "        model=BatchNormalization()(model)\n",
    "        model=LeakyReLU(alpha=0.1)(model)\n",
    "#         model=Conv2DTranspose(4, kernel_size=5, strides=2, padding=\"same\")(model)\n",
    "#         model=BatchNormalization()(model)\n",
    "#         model=LeakyReLU(alpha=0.2)(model)\n",
    "        model=Conv2DTranspose(self.img_shape[2], kernel_size=5, strides=2, padding=\"same\", activation=\"tanh\")(model)\n",
    "        \n",
    "        \n",
    "#         # Use Upsampling2D\n",
    "#         noise = Input(shape=(self.latent_dim,))\n",
    "#         model=Dense(3*3*128, input_dim=self.latent_dim)(noise)\n",
    "#         model=BatchNormalization()(model)\n",
    "#         model=LeakyReLU(alpha=0.2)(model)\n",
    "#         model=Reshape(target_shape=(3,3,128))(model)\n",
    "#         model=Conv2D(64, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(model)\n",
    "#         model=UpSampling2D((2, 2))(model)\n",
    "# #         model=BatchNormalization()(model)\n",
    "# #         model=LeakyReLU(alpha=0.2)(model)\n",
    "#         model=Conv2D(32, kernel_size=3, strides=1, padding=\"same\", activation=\"relu\")(model)\n",
    "#         model=UpSampling2D((2, 2))(model)\n",
    "# #         model=BatchNormalization()(model)\n",
    "# #         model=LeakyReLU(alpha=0.2)(model)\n",
    "#         model=Conv2D(self.img_shape[2], kernel_size=3, strides=1, padding=\"same\")(model)\n",
    "#         model=UpSampling2D((2, 2))(model)\n",
    "#         model=Activation(\"tanh\")(model)\n",
    "        \n",
    "        return Model(noise, model)\n",
    "    \n",
    "    def build_discriminator_CNN(self):\n",
    "        \n",
    "#         self.img_shape=(28,28,1)\n",
    "        im = Input(shape=self.img_shape)\n",
    "        model=Conv2D(16, kernel_size=5, strides=2, padding=\"same\")(im)\n",
    "#         model=BatchNormalization()(model)\n",
    "        model=LeakyReLU(alpha=0.1)(model)\n",
    "        model=Conv2D(32, kernel_size=5, strides=2, padding=\"same\")(model)\n",
    "        model=BatchNormalization()(model)\n",
    "        model=LeakyReLU(alpha=0.1)(model)\n",
    "#         model=Conv2D(32, kernel_size=5, strides=2, padding=\"same\")(model)\n",
    "#         model=BatchNormalization()(model)\n",
    "#         model=LeakyReLU(alpha=0.2)(model)\n",
    "        model=Flatten()(model)\n",
    "        model=Dense(1, activation=\"sigmoid\")(model)\n",
    "        return Model(im, model)\n",
    "    \n",
    "    def boundary_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Boundary seeking loss.\n",
    "        Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\n",
    "        \"\"\"\n",
    "        return 0.5 * K.mean((K.log(y_pred) - K.log(1 - y_pred))**2)\n",
    "\n",
    "    def train(self, X_train, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "#         # Load the dataset\n",
    "#         (X_train, _), (_, _) = mnist.load_data()\n",
    "        self.history=np.zeros((epochs, 4))\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        \n",
    "        dg=datagen_norepeat(batch_size, X_train)# randomly generate data without repeating\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "#             idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            idx=next(dg)# yield next batch\n",
    "            imgs = X_train[idx]\n",
    "            \n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "            # Generate a batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake) # half positive, half negtive\n",
    "            \n",
    "#             d_loss=self.discriminator.train_on_batch(np.vstack((imgs,gen_imgs)), np.vstack((valid,fake)))\n",
    "\n",
    "#             comb_x=np.vstack((imgs,gen_imgs))\n",
    "#             comb_y=np.vstack((valid,fake))\n",
    "#             idx_sh=np.random.shuffle(np.arange(batch_size*2))\n",
    "#             d_loss_real = self.discriminator.train_on_batch(comb_x[0:batch_size], comb_y[0:batch_size])\n",
    "#             d_loss_fake = self.discriminator.train_on_batch(comb_x[batch_size:], comb_y[batch_size:])\n",
    "#             d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch+1, d_loss[0], 100*d_loss[1], g_loss))\n",
    "            self.history[epoch,:]=[epoch+1, d_loss[0], 100*d_loss[1], g_loss]\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % sample_interval == 0:\n",
    "                self.sample_images(epoch)\n",
    "\n",
    "    def sample_images(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, self.latent_dim))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(self.path+\"/mnist_%d.png\" % epoch)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgan.discriminator.save_weights(os.getcwd()+\"/model/bgan_disc_weights_%s_%s.h5\" % (datatype, nntype))\n",
    "bgan.generator.save_weights(os.getcwd()+\"/model/bgan_gene_weights_%s_%s.h5\" % (datatype, nntype))\n",
    "np.save(os.getcwd()+\"/model/hist_%s_batchsize%d_glr%f_dlr%f_%s.npy\" % (datatype, batchsize, glrate, dlrate, nntype),\n",
    "        bgan.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def testplot(img_cont, img_disc):\n",
    "    img_disc=img_disc.reshape(-1,28,28)\n",
    "    r, c = 2, 5\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for j in range(c):\n",
    "        \n",
    "#     for i in range(r):\n",
    "        axs[0,j].imshow(img_cont[cnt, :,:], cmap='gray')\n",
    "        axs[0,j].axis('off')\n",
    "        axs[1,j].imshow(img_disc[cnt, :,:], cmap='gray')\n",
    "        axs[1,j].axis('off')\n",
    "        cnt += 1\n",
    "#         fig.savefig(self.path+\"/mnist_%d.png\" % epoch)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "testplot(X_train_cont, X_train_disc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
